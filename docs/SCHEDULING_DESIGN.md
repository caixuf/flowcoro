# FlowCoro è°ƒåº¦ç³»ç»Ÿè®¾è®¡è¯¦è§£

[English Version](#english-version) | ä¸­æ–‡ç‰ˆ

## é¡¹ç›®ç®€ä»‹

FlowCoro æ˜¯ä¸€ä¸ªåŸºäº C++20 åç¨‹çš„é«˜æ€§èƒ½å¼‚æ­¥ä»»åŠ¡è°ƒåº¦åº“ï¼Œä¸“ä¸º**æ‰¹é‡ä»»åŠ¡å¤„ç†**å’Œ**é«˜ååé‡åœºæ™¯**è®¾è®¡ã€‚

### æ ¸å¿ƒç‰¹ç‚¹

- **ç«‹å³æ‰§è¡Œæ¨¡å‹**: ä½¿ç”¨ `suspend_never` å®ç°ä»»åŠ¡åˆ›å»ºæ—¶ç«‹å³æ‰§è¡Œ
- **æ— é”æ¶æ„**: åŸºäºæ— é”é˜Ÿåˆ—çš„é«˜æ€§èƒ½ä»»åŠ¡åˆ†å‘ï¼Œé¿å…é”ç«äº‰
- **æ™ºèƒ½è´Ÿè½½å‡è¡¡**: è‡ªé€‚åº”é€‰æ‹©æœ€ä¼˜è°ƒåº¦å™¨ï¼Œå®ç°è´Ÿè½½å‡è¡¡
- **å¤šè°ƒåº¦å™¨å¹¶è¡Œ**: å¤šä¸ªç‹¬ç«‹è°ƒåº¦å™¨å¹¶è¡Œå¤„ç†åç¨‹ä»»åŠ¡
- **ä¸‰å±‚è°ƒåº¦æ¶æ„**: æ¸…æ™°çš„åˆ†å±‚è®¾è®¡ï¼ŒèŒè´£æ˜ç¡®

### é€‚ç”¨åœºæ™¯

âœ… **æœ€ä½³é€‚ç”¨åœºæ™¯**:
- Web API æœåŠ¡å™¨ï¼ˆé«˜å¹¶å‘è¯·æ±‚å¤„ç†ï¼‰
- æ‰¹é‡æ•°æ®å¤„ç†ç®¡é“
- é«˜é¢‘äº¤æ˜“ç³»ç»Ÿ
- å¾®æœåŠ¡ç½‘å…³
- çˆ¬è™«ç³»ç»Ÿå’Œå¹¶è¡Œä¸‹è½½
- ç”Ÿäº§è€…-æ¶ˆè´¹è€…æ¨¡å¼ï¼ˆé€šè¿‡ Channelï¼‰

âŒ **ä¸é€‚åˆåœºæ™¯**:
- éœ€è¦ç²¾ç¡®æ§åˆ¶åç¨‹æ‰§è¡Œé¡ºåºçš„åœºæ™¯
- å•ä¸ªé•¿æ—¶é—´è¿è¡Œçš„åç¨‹
- éœ€è¦æ‰‹åŠ¨ç®¡ç†åç¨‹ç”Ÿå‘½å‘¨æœŸçš„åœºæ™¯

## ä¸‰å±‚è°ƒåº¦æ¶æ„

FlowCoro é‡‡ç”¨ä¸‰å±‚è°ƒåº¦æ¶æ„ï¼Œæ¯å±‚èŒè´£æ¸…æ™°ï¼š

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: åç¨‹ç®¡ç†å™¨ (CoroutineManager)              â”‚
â”‚  èŒè´£: åç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†ã€å®šæ—¶å™¨ã€è°ƒåº¦å†³ç­–            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ schedule_coroutine_enhanced()
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: åç¨‹æ±  (CoroutinePool)                     â”‚
â”‚  èŒè´£: å¤šè°ƒåº¦å™¨ç®¡ç†ã€æ™ºèƒ½è´Ÿè½½å‡è¡¡                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ CoroutineScheduler (ç‹¬ç«‹çº¿ç¨‹)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: çº¿ç¨‹æ±  (ThreadPool)                        â”‚
â”‚  èŒè´£: åº•å±‚å·¥ä½œçº¿ç¨‹ç®¡ç†ã€æ— é”ä»»åŠ¡æ‰§è¡Œ                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 1: åç¨‹ç®¡ç†å™¨ (CoroutineManager)

**ä½ç½®**: `include/flowcoro/coroutine_manager.h`

**æ ¸å¿ƒèŒè´£**:
1. åç¨‹ç”Ÿå‘½å‘¨æœŸç®¡ç†ï¼ˆåˆ›å»ºã€é”€æ¯ï¼‰
2. å®šæ—¶å™¨é˜Ÿåˆ—ç®¡ç†ï¼ˆæ”¯æŒ `sleep_for` ç­‰æ“ä½œï¼‰
3. è°ƒåº¦å†³ç­–ï¼ˆé€šè¿‡ `schedule_resume` æŠ•é€’åç¨‹ï¼‰
4. æ‰¹é‡å¤„ç†ä¼˜åŒ–ï¼ˆå®šæ—¶å™¨ã€å°±ç»ªé˜Ÿåˆ—ã€å¾…é”€æ¯é˜Ÿåˆ—ï¼‰

**å…³é”®æ–¹æ³•**:

```cpp
class CoroutineManager {
public:
    // æ ¸å¿ƒè°ƒåº¦æ–¹æ³• - æŠ•é€’åç¨‹åˆ°åç¨‹æ± 
    void schedule_resume(std::coroutine_handle<> handle) {
        if (!handle || handle.done()) return;
        
        // æŠ•é€’åˆ°åç¨‹æ± è¿›è¡Œå¹¶è¡Œå¤„ç†
        schedule_coroutine_enhanced(handle);
    }
    
    // é©±åŠ¨è°ƒåº¦å¾ªç¯ï¼ˆéœ€è¦åœ¨ä¸»çº¿ç¨‹å®šæœŸè°ƒç”¨ï¼‰
    void drive() {
        drive_coroutine_pool();        // é©±åŠ¨åç¨‹æ± 
        process_timer_queue();         // æ‰¹é‡å¤„ç†å®šæ—¶å™¨(32ä¸ª/æ‰¹)
        process_ready_queue();         // æ‰¹é‡å¤„ç†å°±ç»ªé˜Ÿåˆ—(64ä¸ª/æ‰¹)
        process_pending_tasks();       // æ‰¹é‡é”€æ¯åç¨‹(32ä¸ª/æ‰¹)
    }
    
    // æ·»åŠ å®šæ—¶å™¨
    void add_timer(std::chrono::steady_clock::time_point when, 
                   std::coroutine_handle<> handle);
    
    // å•ä¾‹æ¨¡å¼
    static CoroutineManager& get_instance();
};
```

**æ‰¹é‡å¤„ç†ä¼˜åŒ–**:
- **å®šæ—¶å™¨é˜Ÿåˆ—**: æ¯æ¬¡æœ€å¤šå¤„ç† 32 ä¸ªåˆ°æœŸå®šæ—¶å™¨ï¼Œå‡å°‘é”ç«äº‰
- **å°±ç»ªé˜Ÿåˆ—**: æ¯æ¬¡æœ€å¤šå¤„ç† 64 ä¸ªå°±ç»ªåç¨‹ï¼Œæå‡ååé‡
- **é”€æ¯é˜Ÿåˆ—**: æ‰¹é‡é”€æ¯åç¨‹ï¼Œé¿å…é¢‘ç¹åŠ é”

### Layer 2: åç¨‹æ±  (CoroutinePool)

**ä½ç½®**: `src/coroutine_pool.cpp` (å†…éƒ¨å®ç°)

**æ ¸å¿ƒèŒè´£**:
1. ç®¡ç†å¤šä¸ªç‹¬ç«‹çš„åç¨‹è°ƒåº¦å™¨ï¼ˆCoroutineSchedulerï¼‰
2. æ™ºèƒ½è´Ÿè½½å‡è¡¡ï¼Œé€‰æ‹©æœ€ä¼˜è°ƒåº¦å™¨
3. ç»Ÿè®¡ä¿¡æ¯æ”¶é›†å’Œæ€§èƒ½ç›‘æ§
4. ç®¡ç†åå°çº¿ç¨‹æ± å¤„ç† CPU å¯†é›†å‹ä»»åŠ¡

**æ¶æ„è®¾è®¡**:

```cpp
class CoroutinePool {
private:
    // æ ¹æ® CPU æ ¸å¿ƒæ•°ç¡®å®šè°ƒåº¦å™¨æ•°é‡ï¼ˆå½“å‰é…ç½®ä¸º 1 ä¸ªï¼‰
    const size_t NUM_SCHEDULERS;
    
    // ç‹¬ç«‹åç¨‹è°ƒåº¦å™¨ï¼Œæ¯ä¸ªè¿è¡Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­
    std::vector<std::unique_ptr<CoroutineScheduler>> schedulers_;
    
    // åå°çº¿ç¨‹æ±  - å¤„ç† CPU å¯†é›†å‹ä»»åŠ¡
    std::unique_ptr<lockfree::ThreadPool> thread_pool_;
    
public:
    // åç¨‹è°ƒåº¦ - ä½¿ç”¨æ™ºèƒ½è´Ÿè½½å‡è¡¡
    void schedule_coroutine(std::coroutine_handle<> handle) {
        // ä½¿ç”¨æ™ºèƒ½è´Ÿè½½å‡è¡¡å™¨é€‰æ‹©æœ€ä¼˜è°ƒåº¦å™¨
        auto& load_balancer = CoroutineManager::get_instance()
                                .get_load_balancer();
        size_t scheduler_index = load_balancer.select_scheduler();
        
        // åˆ†é…ç»™å¯¹åº”çš„è°ƒåº¦å™¨
        schedulers_[scheduler_index]->schedule_coroutine(handle);
    }
    
    // CPU å¯†é›†å‹ä»»åŠ¡æäº¤åˆ°åå°çº¿ç¨‹æ± 
    void schedule_task(std::function<void()> task) {
        thread_pool_->enqueue(std::move(task));
    }
};
```

**è°ƒåº¦å™¨é…ç½®**:
- **è°ƒåº¦å™¨æ•°é‡**: å½“å‰ä¼˜åŒ–ä¸º 1 ä¸ªè°ƒåº¦å™¨ï¼ˆæ€§èƒ½æœ€ä¼˜é…ç½®ï¼‰
- **çº¿ç¨‹æ± å¤§å°**: 8-24 ä¸ªå·¥ä½œçº¿ç¨‹ï¼ˆæ ¹æ® CPU æ ¸å¿ƒæ•°è‡ªé€‚åº”ï¼‰
- **CPU äº²å’Œæ€§**: æ¯ä¸ªè°ƒåº¦å™¨ç»‘å®šåˆ°ç‰¹å®š CPU æ ¸å¿ƒï¼Œå‡å°‘çº¿ç¨‹è¿ç§»å¼€é”€

### Layer 3: åç¨‹è°ƒåº¦å™¨ (CoroutineScheduler)

**ä½ç½®**: `src/coroutine_pool.cpp` (å†…éƒ¨å®ç°)

**æ ¸å¿ƒèŒè´£**:
1. è¿è¡Œåœ¨ç‹¬ç«‹çº¿ç¨‹ä¸­ï¼ŒæŒç»­å¤„ç†åç¨‹
2. ç®¡ç†æ— é”åç¨‹é˜Ÿåˆ—
3. æ‰¹é‡æ‰§è¡Œåç¨‹ï¼Œæå‡ç¼“å­˜å‘½ä¸­ç‡
4. å®ç°è‡ªé€‚åº”ç­‰å¾…ç­–ç•¥ï¼Œå‡å°‘ CPU ç©ºè½¬

**å…³é”®ç‰¹æ€§**:

```cpp
class CoroutineScheduler {
private:
    // æ— é”åç¨‹é˜Ÿåˆ—
    lockfree::Queue<std::coroutine_handle<>> coroutine_queue_;
    
    // ç²¾ç¡®çš„é˜Ÿåˆ—é•¿åº¦ç»Ÿè®¡
    std::atomic<size_t> queue_size_{0};
    
    // å·¥ä½œçº¿ç¨‹
    void worker_loop() {
        const size_t BATCH_SIZE = 256; // æ‰¹å¤„ç†å¤§å°
        std::vector<std::coroutine_handle<>> batch;
        
        while (!stop_flag_) {
            // æ‰¹é‡æå–åç¨‹
            while (batch.size() < BATCH_SIZE && 
                   coroutine_queue_.dequeue(handle)) {
                batch.push_back(handle);
                queue_size_.fetch_sub(1);
            }
            
            // æ‰¹é‡æ‰§è¡Œåç¨‹
            for (auto handle : batch) {
                if (handle && !handle.done()) {
                    handle.resume();
                    completed_coroutines_.fetch_add(1);
                    load_balancer_.on_task_completed(scheduler_id_);
                }
            }
            
            // è‡ªé€‚åº”ç­‰å¾…ç­–ç•¥ï¼ˆ4 çº§ç­‰å¾…ï¼‰
            if (batch.empty()) {
                // Level 1: è‡ªæ—‹ç­‰å¾…ï¼ˆæœ€å¿«å“åº”ï¼‰
                // Level 2: yield è®©å‡º CPU
                // Level 3: çŸ­æš‚ä¼‘çœ 
                // Level 4: æ¡ä»¶å˜é‡ç­‰å¾…
            }
        }
    }
    
public:
    void schedule_coroutine(std::coroutine_handle<> handle) {
        // æ·»åŠ åˆ°æ— é”é˜Ÿåˆ—
        coroutine_queue_.enqueue(handle);
        queue_size_.fetch_add(1);
        
        // æ›´æ–°è´Ÿè½½å‡è¡¡å™¨
        load_balancer_.update_load(scheduler_id_, queue_size_);
        
        // å”¤é†’å·¥ä½œçº¿ç¨‹
        cv_.notify_one();
    }
};
```

**æ€§èƒ½ä¼˜åŒ–**:
- **æ‰¹é‡å¤„ç†**: æ¯æ¬¡æœ€å¤šå¤„ç† 256 ä¸ªåç¨‹ï¼Œå‡å°‘é˜Ÿåˆ—è®¿é—®å¼€é”€
- **é¢„å–ä¼˜åŒ–**: ä½¿ç”¨ `__builtin_prefetch` é¢„å–å†…å­˜ï¼Œæå‡ç¼“å­˜å‘½ä¸­ç‡
- **CPU äº²å’Œæ€§**: ç»‘å®šåˆ°ç‰¹å®š CPU æ ¸å¿ƒï¼Œå‡å°‘ç¼“å­˜å¤±æ•ˆ
- **å››çº§ç­‰å¾…ç­–ç•¥**: æ ¹æ®ç©ºé—²æ—¶é—´è‡ªé€‚åº”è°ƒæ•´ç­‰å¾…ç­–ç•¥

## æ™ºèƒ½è´Ÿè½½å‡è¡¡

**ä½ç½®**: `include/flowcoro/load_balancer.h`

### è®¾è®¡ç›®æ ‡

1. **å¿«é€Ÿé€‰æ‹©**: æœ€å°åŒ–è°ƒåº¦å™¨é€‰æ‹©çš„å¼€é”€
2. **è´Ÿè½½å‡è¡¡**: é¿å…æŸäº›è°ƒåº¦å™¨è¿‡è½½
3. **æ— é”è®¾è®¡**: ä½¿ç”¨åŸå­æ“ä½œé¿å…é”ç«äº‰

### å®ç°æœºåˆ¶

```cpp
class SmartLoadBalancer {
private:
    // æ¯ä¸ªè°ƒåº¦å™¨çš„é˜Ÿåˆ—è´Ÿè½½
    std::array<std::atomic<size_t>, MAX_SCHEDULERS> queue_loads_;
    
    // è½®è¯¢è®¡æ•°å™¨
    std::atomic<size_t> round_robin_counter_{0};
    
public:
    // æ··åˆç­–ç•¥ï¼šè½®è¯¢ + è´Ÿè½½æ„ŸçŸ¥
    size_t select_scheduler() {
        size_t count = scheduler_count_.load();
        
        // å¿«é€Ÿè·¯å¾„ï¼šä½¿ç”¨è½®è¯¢ï¼ˆæ€§èƒ½æ›´å¥½ï¼‰
        size_t quick_choice = round_robin_counter_.fetch_add(1) % count;
        
        // æ¯ 16 æ¬¡æ‰§è¡Œä¸€æ¬¡è´Ÿè½½æ£€æŸ¥ï¼ˆä¼˜åŒ–ï¼šå‡å°‘å¼€é”€ï¼‰
        if ((quick_choice & 0xF) == 0) {
            // é€‰æ‹©è´Ÿè½½æœ€å°çš„è°ƒåº¦å™¨
            size_t min_load = SIZE_MAX;
            size_t best_scheduler = 0;
            
            for (size_t i = 0; i < count; ++i) {
                size_t load = queue_loads_[i].load(std::memory_order_relaxed);
                if (load < min_load) {
                    min_load = load;
                    best_scheduler = i;
                }
            }
            return best_scheduler;
        }
        
        return quick_choice;
    }
    
    // æ›´æ–°è°ƒåº¦å™¨è´Ÿè½½
    void update_load(size_t scheduler_id, size_t load) {
        queue_loads_[scheduler_id].store(load, std::memory_order_relaxed);
    }
    
    // ä»»åŠ¡å®Œæˆæ—¶é€’å‡è´Ÿè½½
    void on_task_completed(size_t scheduler_id) {
        queue_loads_[scheduler_id].fetch_sub(1, std::memory_order_relaxed);
    }
};
```

### è´Ÿè½½å‡è¡¡ç­–ç•¥

**æ··åˆç­–ç•¥**ï¼ˆè½®è¯¢ + è´Ÿè½½æ„ŸçŸ¥ï¼‰:

1. **é»˜è®¤æƒ…å†µ**: ä½¿ç”¨è½®è¯¢ï¼ˆRound-Robinï¼‰ç­–ç•¥
   - ä¼˜ç‚¹: éå¸¸å¿«é€Ÿï¼Œæ— éœ€è®¡ç®—
   - é€šè¿‡åŸå­è®¡æ•°å™¨å®ç°: `round_robin_counter_.fetch_add(1) % count`

2. **å®šæœŸæ£€æŸ¥**: æ¯ 16 æ¬¡è°ƒåº¦æ‰§è¡Œä¸€æ¬¡è´Ÿè½½æ£€æŸ¥
   - éå†æ‰€æœ‰è°ƒåº¦å™¨ï¼Œæ‰¾åˆ°é˜Ÿåˆ—é•¿åº¦æœ€å°çš„
   - è¿”å›è´Ÿè½½æœ€è½»çš„è°ƒåº¦å™¨ç´¢å¼•

3. **å®æ—¶æ›´æ–°**: åç¨‹è°ƒåº¦å’Œå®Œæˆæ—¶å®æ—¶æ›´æ–°è´Ÿè½½ä¿¡æ¯
   - `schedule_coroutine`: å¢åŠ é˜Ÿåˆ—è´Ÿè½½
   - `on_task_completed`: å‡å°‘é˜Ÿåˆ—è´Ÿè½½

**ä¼˜åŠ¿**:
- âš¡ **é«˜æ€§èƒ½**: 95% çš„è°ƒåº¦ä½¿ç”¨å¿«é€Ÿè½®è¯¢ï¼Œå¼€é”€æå°
- ğŸ“Š **è´Ÿè½½å‡è¡¡**: å®šæœŸæ£€æŸ¥ç¡®ä¿è´Ÿè½½ç›¸å¯¹å‡è¡¡
- ğŸ”’ **æ— é”è®¾è®¡**: ä½¿ç”¨åŸå­æ“ä½œï¼Œé¿å…é”ç«äº‰
- ğŸ¯ **è‡ªé€‚åº”**: æ ¹æ®å®é™…è´Ÿè½½åŠ¨æ€è°ƒæ•´

## ä»»åŠ¡æ‰§è¡Œæµç¨‹

### å®Œæ•´æ‰§è¡Œæµç¨‹

```text
1. ç”¨æˆ·åˆ›å»º Task
   â†“
2. Task æ„é€ å‡½æ•°è°ƒç”¨ initial_suspend()
   â†“ (è¿”å› suspend_never)
3. åç¨‹ä½“ç«‹å³å¼€å§‹æ‰§è¡Œ
   â†“
4. é‡åˆ° co_awaitï¼ˆå¦‚ sleep_forï¼‰
   â†“ (è¿”å› suspend_always)
5. åç¨‹æŒ‚èµ·ï¼ŒæŠ•é€’åˆ° CoroutineManager
   â†“ schedule_resume()
6. CoroutineManager è°ƒç”¨ schedule_coroutine_enhanced()
   â†“
7. CoroutinePool ä½¿ç”¨æ™ºèƒ½è´Ÿè½½å‡è¡¡é€‰æ‹©è°ƒåº¦å™¨
   â†“ select_scheduler()
8. åç¨‹è¿›å…¥é€‰ä¸­çš„ CoroutineScheduler çš„æ— é”é˜Ÿåˆ—
   â†“ coroutine_queue_.enqueue()
9. è°ƒåº¦å™¨å·¥ä½œçº¿ç¨‹æ‰¹é‡æå–åç¨‹
   â†“ batch.push_back()
10. æ‰¹é‡æ¢å¤åç¨‹æ‰§è¡Œ
    â†“ handle.resume()
11. åç¨‹ç»§ç»­æ‰§è¡Œç›´åˆ°å®Œæˆæˆ–å†æ¬¡æŒ‚èµ·
    â†“
12. å®Œæˆï¼šæ›´æ–°ç»Ÿè®¡ä¿¡æ¯ï¼Œé€šçŸ¥è´Ÿè½½å‡è¡¡å™¨
```

### suspend_never æœºåˆ¶è¯¦è§£

FlowCoro çš„ä¸€ä¸ªå…³é”®è®¾è®¡æ˜¯ **Task ç«‹å³æ‰§è¡Œ** æ¨¡å‹ï¼š

```cpp
Task<int> compute(int x) {
    // 1. Task å¯¹è±¡åˆ›å»º
    // 2. initial_suspend() è¿”å› suspend_never
    // 3. åç¨‹ä½“ç«‹å³å¼€å§‹æ‰§è¡Œï¼ˆä¸ç­‰å¾…è°ƒåº¦ï¼‰
    
    co_await sleep_for(std::chrono::milliseconds(50));
    // 4. é‡åˆ° co_awaitï¼Œè¿”å› suspend_always
    // 5. æ­¤æ—¶åç¨‹æ‰çœŸæ­£æŒ‚èµ·ï¼ŒæŠ•é€’åˆ°è°ƒåº¦ç³»ç»Ÿ
    
    co_return x * x;
}

// ä½¿ç”¨ç¤ºä¾‹
Task task1 = compute(10);  // ç«‹å³å¼€å§‹æ‰§è¡Œ
Task task2 = compute(20);  // ç«‹å³å¼€å§‹æ‰§è¡Œï¼ˆå¹¶å‘ï¼‰
Task task3 = compute(30);  // ç«‹å³å¼€å§‹æ‰§è¡Œï¼ˆå¹¶å‘ï¼‰

// ä¸‰ä¸ªä»»åŠ¡å·²ç»åœ¨ä¸åŒè°ƒåº¦å™¨ä¸Šå¹¶å‘è¿è¡Œ
auto result1 = co_await task1;  // ç­‰å¾…ç»“æœ
auto result2 = co_await task2;
auto result3 = co_await task3;
```

**suspend_never çš„ä¼˜åŠ¿**:

1. **æœ€å¤§åŒ–å¹¶å‘åº¦**: ä»»åŠ¡åˆ›å»ºæ—¶ç«‹å³å¼€å§‹æ‰§è¡Œï¼Œæ— éœ€ç­‰å¾…è°ƒåº¦
2. **å‡å°‘å»¶è¿Ÿ**: é¿å…äº†"åˆ›å»º â†’ ç­‰å¾…è°ƒåº¦ â†’ å¼€å§‹æ‰§è¡Œ"çš„å»¶è¿Ÿ
3. **ç®€åŒ– API**: ç”¨æˆ·æ— éœ€æ‰‹åŠ¨å¯åŠ¨ä»»åŠ¡ï¼Œåˆ›å»ºå³æ‰§è¡Œ
4. **å¤©ç„¶å¹¶å‘**: å¤šä¸ªä»»åŠ¡åˆ›å»ºæ—¶è‡ªåŠ¨å¹¶å‘æ‰§è¡Œ

**å¯¹æ¯”å…¶ä»–æ¨¡å‹**:

| æ¨¡å‹ | åˆ›å»ºæ—¶è¡Œä¸º | ä½•æ—¶å¼€å§‹æ‰§è¡Œ | é€‚ç”¨åœºæ™¯ |
|------|-----------|-------------|---------|
| **suspend_never** (FlowCoro) | ç«‹å³æ‰§è¡Œ | åˆ›å»ºæ—¶ | æ‰¹é‡å¹¶å‘ä»»åŠ¡ |
| **suspend_always** | æŒ‚èµ·ç­‰å¾… | éœ€è¦æ‰‹åŠ¨è°ƒåº¦ | éœ€è¦ç²¾ç¡®æ§åˆ¶æ‰§è¡Œæ—¶æœº |
| **Go goroutine** | æŒ‚èµ·ç­‰å¾… | è°ƒåº¦å™¨åˆ†é…æ—¶ | å¤§é‡è½»é‡çº§å¹¶å‘ |
| **Rust Tokio** | æŒ‚èµ·ç­‰å¾… | .await æ—¶ | ç²¾ç¡®æ§åˆ¶å¼‚æ­¥æµç¨‹ |

### å®šæ—¶å™¨å¤„ç†

FlowCoro æ”¯æŒä¸“ç”¨å®šæ—¶å™¨çº¿ç¨‹å’Œæ‰¹é‡å®šæ—¶å™¨å¤„ç†ï¼š

```cpp
// æ·»åŠ å®šæ—¶å™¨
manager.add_timer_enhanced(
    std::chrono::steady_clock::now() + std::chrono::milliseconds(100),
    handle
);

// å®šæ—¶å™¨å¤„ç†æµç¨‹
void dedicated_timer_thread_func() {
    while (!stop_) {
        // 1. ç­‰å¾…åˆ°æœŸçš„å®šæ—¶å™¨
        // 2. æ‰¹é‡æå–åˆ°æœŸçš„åç¨‹
        // 3. é€šè¿‡ schedule_coroutine_enhanced æŠ•é€’åˆ°åç¨‹æ± 
        // 4. ç²¾ç¡®ç­‰å¾…åˆ°ä¸‹ä¸€ä¸ªå®šæ—¶å™¨æ—¶é—´
    }
}
```

**ä¼˜åŠ¿**:
- â° **ç²¾ç¡®å®šæ—¶**: ä¸“ç”¨çº¿ç¨‹ç¡®ä¿å®šæ—¶å™¨ç²¾ç¡®è§¦å‘
- ğŸ“¦ **æ‰¹é‡å¤„ç†**: åŒæ—¶åˆ°æœŸçš„å®šæ—¶å™¨æ‰¹é‡å¤„ç†ï¼Œæå‡æ•ˆç‡
- ğŸ”“ **æ— é”æŠ•é€’**: å®šæ—¶å™¨åˆ°æœŸåé€šè¿‡æ— é”é˜Ÿåˆ—æŠ•é€’åç¨‹

## çº¿ç¨‹æ± å®ç°

**ä½ç½®**: `include/flowcoro/thread_pool.h`

### æ— é”çº¿ç¨‹æ±  (ThreadPool)

```cpp
class ThreadPool {
private:
    // æ— é”ä»»åŠ¡é˜Ÿåˆ—
    lockfree::Queue<std::function<void()>> task_queue_;
    
    // å·¥ä½œçº¿ç¨‹æ•°ç»„
    std::vector<std::thread> workers_;
    
    void worker_loop() {
        std::function<void()> task;
        
        while (!stop_) {
            if (task_queue_.dequeue(task)) {
                task();  // æ‰§è¡Œä»»åŠ¡
            } else {
                // è‡ªé€‚åº”ç­‰å¾…ç­–ç•¥
                std::this_thread::yield();
            }
        }
    }
    
public:
    // æäº¤ä»»åŠ¡
    void enqueue_void(std::function<void()> task) {
        task_queue_.enqueue(std::move(task));
    }
};
```

**ç‰¹ç‚¹**:
- ğŸ”’ **æ— é”é˜Ÿåˆ—**: ä½¿ç”¨ `lockfree::Queue` é¿å…é”ç«äº‰
- ğŸ§µ **è‡ªé€‚åº”çº¿ç¨‹æ•°**: æ ¹æ® CPU æ ¸å¿ƒæ•°è°ƒæ•´å·¥ä½œçº¿ç¨‹
- âš¡ **é«˜ååé‡**: æ‰¹é‡ä»»åŠ¡å¤„ç†èƒ½åŠ›å¼º

### å·¥ä½œçªƒå–çº¿ç¨‹æ±  (WorkStealingThreadPool)

æ”¯æŒå·¥ä½œçªƒå–ç®—æ³•çš„é«˜çº§çº¿ç¨‹æ± ï¼š

```cpp
class WorkStealingThreadPool {
private:
    // æ¯ä¸ªå·¥ä½œçº¿ç¨‹æœ‰ç‹¬ç«‹çš„æœ¬åœ°é˜Ÿåˆ—
    std::vector<std::unique_ptr<WorkerData>> worker_data_;
    
    // å…¨å±€é˜Ÿåˆ—
    lockfree::Queue<std::function<void()>> global_queue_;
    
    void worker_loop(size_t worker_index) {
        // 1. å…ˆæ£€æŸ¥æœ¬åœ°é˜Ÿåˆ—
        // 2. æ£€æŸ¥å…¨å±€é˜Ÿåˆ—
        // 3. å°è¯•ä»å…¶ä»–å·¥ä½œçº¿ç¨‹å·å–ä»»åŠ¡
    }
};
```

**å·¥ä½œçªƒå–ç­–ç•¥**:
1. ä¼˜å…ˆå¤„ç†æœ¬åœ°é˜Ÿåˆ—ï¼ˆå‡å°‘ç«äº‰ï¼‰
2. æœ¬åœ°é˜Ÿåˆ—ç©ºæ—¶æ£€æŸ¥å…¨å±€é˜Ÿåˆ—
3. å…¨å±€é˜Ÿåˆ—ç©ºæ—¶ä»å…¶ä»–çº¿ç¨‹çªƒå–ä»»åŠ¡
4. å®ç°è´Ÿè½½å‡è¡¡

## æ— é”é˜Ÿåˆ—å®ç°

**ä½ç½®**: `include/flowcoro/lockfree.h`

FlowCoro çš„æ ¸å¿ƒæ€§èƒ½æ¥è‡ªäºæ— é”é˜Ÿåˆ—çš„é«˜æ•ˆå®ç°ï¼š

```cpp
template<typename T>
class Queue {
private:
    struct Node {
        std::atomic<T*> data;
        std::atomic<Node*> next;
    };
    
    std::atomic<Node*> head_;
    std::atomic<Node*> tail_;
    
public:
    void enqueue(T value) {
        // Michael-Scott æ— é”é˜Ÿåˆ—ç®—æ³•
        // ä½¿ç”¨ CAS (Compare-And-Swap) åŸå­æ“ä½œ
    }
    
    bool dequeue(T& value) {
        // æ— é”å‡ºé˜Ÿæ“ä½œ
        // å¤„ç† ABA é—®é¢˜
    }
};
```

**å…³é”®ç‰¹æ€§**:
- ğŸ”’ **å®Œå…¨æ— é”**: åŸºäº CAS åŸå­æ“ä½œ
- ğŸ”¥ **é«˜å¹¶å‘**: æ”¯æŒå¤šç”Ÿäº§è€…å¤šæ¶ˆè´¹è€…
- ğŸ“ˆ **å¯æ‰©å±•**: æ€§èƒ½éš CPU æ ¸å¿ƒæ•°çº¿æ€§æå‡
- ğŸ›¡ï¸ **ABA å®‰å…¨**: æ­£ç¡®å¤„ç† ABA é—®é¢˜

## æ€§èƒ½ä¼˜åŒ–æŠ€æœ¯

### 1. æ‰¹é‡å¤„ç†

**æ‰€æœ‰é˜Ÿåˆ—æ“ä½œéƒ½é‡‡ç”¨æ‰¹é‡å¤„ç†**:
- å®šæ—¶å™¨é˜Ÿåˆ—: 32 ä¸ª/æ‰¹
- å°±ç»ªé˜Ÿåˆ—: 64 ä¸ª/æ‰¹
- é”€æ¯é˜Ÿåˆ—: 64 ä¸ª/æ‰¹
- åç¨‹æ‰§è¡Œ: 256 ä¸ª/æ‰¹

**ä¼˜åŠ¿**: å‡å°‘é”ç«äº‰ã€æå‡ç¼“å­˜å‘½ä¸­ç‡ã€åˆ†æ‘Šé˜Ÿåˆ—è®¿é—®å¼€é”€

### 2. CPU äº²å’Œæ€§

```cpp
void set_cpu_affinity() {
#ifdef __linux__
    cpu_set_t cpuset;
    CPU_ZERO(&cpuset);
    CPU_SET(scheduler_id_ % std::thread::hardware_concurrency(), &cpuset);
    pthread_setaffinity_np(pthread_self(), sizeof(cpu_set_t), &cpuset);
#endif
}
```

**ä¼˜åŠ¿**: å‡å°‘çº¿ç¨‹è¿ç§»ã€æå‡ç¼“å­˜äº²å’Œæ€§ã€é™ä½å»¶è¿Ÿ

### 3. å†…å­˜é¢„å–

```cpp
while (batch.size() < BATCH_SIZE && coroutine_queue_.dequeue(handle)) {
    batch.push_back(handle);
    
    // é¢„å–ä¸‹ä¸€ä¸ªåç¨‹çš„å†…å­˜
    if (batch.size() < BATCH_SIZE - 1) {
        __builtin_prefetch(handle.address(), 0, 3);
    }
}
```

**ä¼˜åŠ¿**: å‡å°‘å†…å­˜è®¿é—®å»¶è¿Ÿã€æå‡ L1/L2 ç¼“å­˜å‘½ä¸­ç‡

### 4. è‡ªé€‚åº”ç­‰å¾…ç­–ç•¥

**å››çº§ç­‰å¾…ç­–ç•¥**ï¼ˆä»å¿«åˆ°æ…¢ï¼‰:

```cpp
if (empty_iterations < 64) {
    // Level 1: è‡ªæ—‹ç­‰å¾…ï¼ˆæœ€å¿«å“åº”ï¼Œé€‚åˆçŸ­æ—¶é—´ç­‰å¾…ï¼‰
    for (int i = 0; i < 64; ++i) {
        if (!queue.empty()) break;
        __builtin_ia32_pause(); // CPU pause æŒ‡ä»¤
    }
} else if (empty_iterations < 256) {
    // Level 2: yieldï¼ˆè®©å‡º CPUï¼‰
    std::this_thread::yield();
} else if (empty_iterations < 1024) {
    // Level 3: çŸ­æš‚ä¼‘çœ ï¼ˆå¾®ç§’çº§ï¼‰
    std::this_thread::sleep_for(wait_duration);
} else {
    // Level 4: æ¡ä»¶å˜é‡ç­‰å¾…ï¼ˆæ¯«ç§’çº§ï¼‰
    cv_.wait_for(lock, max_wait);
}
```

**ä¼˜åŠ¿**: 
- ä½è´Ÿè½½æ—¶å‡å°‘ CPU ä½¿ç”¨
- é«˜è´Ÿè½½æ—¶å¿«é€Ÿå“åº”
- è‡ªé€‚åº”è°ƒæ•´ï¼Œå¹³è¡¡å»¶è¿Ÿå’Œ CPU ä½¿ç”¨

### 5. å†…å­˜æ± ä¼˜åŒ–

ä½¿ç”¨ Redis/Nginx å¯å‘çš„å†…å­˜æ± è®¾è®¡:

```cpp
// ä½¿ç”¨å†…å­˜æ± åˆ†é…
auto task = std::allocate_shared<std::packaged_task<return_type()>>(
    flowcoro::PoolAllocator<std::packaged_task<return_type()>>{},
    std::bind(std::forward<F>(f), std::forward<Args>(args)...)
);
```

**ä¼˜åŠ¿**: 
- å‡å°‘ malloc/free è°ƒç”¨
- æå‡å†…å­˜åˆ†é…æ€§èƒ½
- é™ä½å†…å­˜ç¢ç‰‡

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```cpp
#include <flowcoro.hpp>
using namespace flowcoro;

// ç®€å•åç¨‹ä»»åŠ¡
Task<int> compute(int value) {
    co_await sleep_for(std::chrono::milliseconds(10));
    co_return value * 2;
}

int main() {
    // ä»»åŠ¡åˆ›å»ºæ—¶ç«‹å³å¼€å§‹æ‰§è¡Œï¼ˆsuspend_neverï¼‰
    auto task1 = compute(10);
    auto task2 = compute(20);
    auto task3 = compute(30);
    
    // ç­‰å¾…ç»“æœ
    auto result1 = sync_wait(task1);
    auto result2 = sync_wait(task2);
    auto result3 = sync_wait(task3);
    
    std::cout << "Results: " << result1 << ", " 
              << result2 << ", " << result3 << std::endl;
    
    return 0;
}
```

### å¹¶å‘æ‰§è¡Œ

```cpp
Task<void> parallel_processing() {
    std::vector<Task<int>> tasks;
    
    // åˆ›å»º 1000 ä¸ªå¹¶å‘ä»»åŠ¡
    for (int i = 0; i < 1000; ++i) {
        tasks.push_back(compute(i));
    }
    
    // æ‰€æœ‰ä»»åŠ¡å·²ç»åœ¨å¹¶å‘æ‰§è¡Œ
    // ç­‰å¾…æ‰€æœ‰ç»“æœ
    for (auto& task : tasks) {
        auto result = co_await task;
        std::cout << "Result: " << result << std::endl;
    }
    
    co_return;
}
```

### Channel é€šä¿¡

```cpp
Task<void> producer_consumer() {
    auto channel = make_channel<int>(100);  // ç¼“å†²åŒºå¤§å°: 100
    
    // ç”Ÿäº§è€…
    auto producer = [channel]() -> Task<void> {
        for (int i = 0; i < 1000; ++i) {
            co_await channel->send(i);
        }
        channel->close();
    };
    
    // æ¶ˆè´¹è€…
    auto consumer = [channel]() -> Task<void> {
        while (true) {
            auto value = co_await channel->recv();
            if (!value.has_value()) break;
            process(value.value());
        }
    };
    
    auto prod_task = producer();
    auto cons_task = consumer();
    
    co_await prod_task;
    co_await cons_task;
    
    co_return;
}
```

## æ€§èƒ½ç‰¹å¾

### ååé‡

- **åç¨‹åˆ›å»ºå’Œæ‰§è¡Œ**: ä¸ Go å’Œ Rust ç›¸å½“
- **æ— é”é˜Ÿåˆ—**: é«˜å¹¶å‘åœºæ™¯ä¸‹æ€§èƒ½ä¼˜å¼‚
- **æ‰¹é‡å¤„ç†**: 10 ä¸‡ä»»åŠ¡å¤„ç†æ—¶é—´ < 1 ç§’

### å»¶è¿Ÿ

- **ä»»åŠ¡è°ƒåº¦å»¶è¿Ÿ**: å¾®ç§’çº§
- **å®šæ—¶å™¨ç²¾åº¦**: æ¯«ç§’çº§ï¼ˆå–å†³äºç³»ç»Ÿå®šæ—¶å™¨ç²¾åº¦ï¼‰
- **ä¸Šä¸‹æ–‡åˆ‡æ¢**: æä½ï¼ˆæ— é”è®¾è®¡ï¼‰

### å¯æ‰©å±•æ€§

- **CPU æ ¸å¿ƒ**: æ€§èƒ½éšæ ¸å¿ƒæ•°çº¿æ€§æå‡ï¼ˆ8-24 æ ¸æœ€ä¼˜ï¼‰
- **å¹¶å‘ä»»åŠ¡æ•°**: æ”¯æŒ 10K+ å¹¶å‘ä»»åŠ¡
- **è°ƒåº¦å™¨æ•°é‡**: å½“å‰ä¼˜åŒ–ä¸º 1 ä¸ªï¼ˆé¿å…è¿‡åº¦è°ƒåº¦å¼€é”€ï¼‰

## è°ƒè¯•å’Œç›‘æ§

### ç»Ÿè®¡ä¿¡æ¯

```cpp
// æ‰“å°åç¨‹æ± ç»Ÿè®¡ä¿¡æ¯
print_pool_stats();

// è¾“å‡ºç¤ºä¾‹:
// === FlowCoro å¤šè°ƒåº¦å™¨åç¨‹æ± ç»Ÿè®¡ ===
//  è¿è¡Œæ—¶é—´: 5234 ms
//  æ¶æ„æ¨¡å¼: 1ä¸ªç‹¬ç«‹åç¨‹è°ƒåº¦å™¨ + åå°çº¿ç¨‹æ± 
//  å·¥ä½œçº¿ç¨‹: 16 ä¸ª
//  å¾…å¤„ç†åç¨‹: 42
//  æ€»åç¨‹æ•°: 10000
//  å®Œæˆåç¨‹: 9958
//  åç¨‹å®Œæˆç‡: 99.6%
```

### æ€§èƒ½ç›‘æ§

```cpp
// è·å–æ€§èƒ½ç»Ÿè®¡
auto stats = get_flowcoro_stats();

std::cout << "ä»»åŠ¡å®Œæˆæ•°: " << stats.tasks_completed << std::endl;
std::cout << "å¹³å‡å»¶è¿Ÿ: " << stats.average_latency_us << " Î¼s" << std::endl;
```

### è°ƒè¯•å·¥å…·

```cpp
// æ‰“å°ç³»ç»ŸçŠ¶æ€
flowcoro::debug::print_system_status();

// æ£€æŸ¥å†…å­˜ä½¿ç”¨
flowcoro::debug::check_memory_usage();

// éªŒè¯åç¨‹çŠ¶æ€ä¸€è‡´æ€§
bool valid = flowcoro::debug::validate_coroutine_state();

// è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•
flowcoro::debug::run_performance_benchmark(10000);
```

## å¸¸è§é—®é¢˜

### Q1: ä¸ºä»€ä¹ˆåªä½¿ç”¨ 1 ä¸ªè°ƒåº¦å™¨ï¼Ÿ

**A**: ç»è¿‡æ€§èƒ½æµ‹è¯•ï¼Œ1 ä¸ªè°ƒåº¦å™¨é…åˆå¤šä¸ªå·¥ä½œçº¿ç¨‹æ˜¯å½“å‰æœ€ä¼˜é…ç½®ï¼š
- å‡å°‘è°ƒåº¦å™¨é—´çš„ç«äº‰
- ç®€åŒ–è´Ÿè½½å‡è¡¡é€»è¾‘
- é™ä½çº¿ç¨‹è°ƒåº¦å¼€é”€
- é…åˆåå°çº¿ç¨‹æ± æä¾›å……è¶³çš„å¹¶å‘èƒ½åŠ›

### Q2: å¦‚ä½•æ§åˆ¶åç¨‹æ‰§è¡Œé¡ºåºï¼Ÿ

**A**: FlowCoro é‡‡ç”¨ suspend_never æ¨¡å‹ï¼Œä»»åŠ¡åˆ›å»ºæ—¶ç«‹å³æ‰§è¡Œï¼Œä¸ä¿è¯æ‰§è¡Œé¡ºåºã€‚å¦‚æœéœ€è¦é¡ºåºæ‰§è¡Œï¼š
```cpp
auto result1 = co_await task1;  // ç­‰å¾… task1 å®Œæˆ
auto task2 = compute(result1);  // ä½¿ç”¨ result1 åˆ›å»º task2
auto result2 = co_await task2;  // ç­‰å¾… task2 å®Œæˆ
```

### Q3: å¦‚ä½•å¤„ç†å¼‚å¸¸ï¼Ÿ

**A**: FlowCoro åœ¨å¤šä¸ªå±‚çº§å¤„ç†å¼‚å¸¸ï¼š
- åç¨‹æ‰§è¡Œå±‚: æ•è·å¹¶è®°å½•å¼‚å¸¸ï¼Œä¸å½±å“è°ƒåº¦å™¨ç¨³å®šæ€§
- ä»»åŠ¡æäº¤å±‚: ä½¿ç”¨ try-catch åŒ…è£…ä»»åŠ¡æ‰§è¡Œ
- ç”¨æˆ·ä»£ç : å»ºè®®ä½¿ç”¨ try-catch æ•è·ä¸šåŠ¡å¼‚å¸¸

```cpp
Task<int> safe_compute(int x) {
    try {
        co_await risky_operation(x);
        co_return x * x;
    } catch (const std::exception& e) {
        std::cerr << "Error: " << e.what() << std::endl;
        co_return -1;
    }
}
```

### Q4: å¦‚ä½•ä¼˜åŒ–æ€§èƒ½ï¼Ÿ

**A**: æ€§èƒ½ä¼˜åŒ–å»ºè®®ï¼š
1. **æ‰¹é‡æäº¤ä»»åŠ¡**: ä¸€æ¬¡æ€§åˆ›å»ºå¤šä¸ªä»»åŠ¡ï¼Œåˆ©ç”¨å¹¶å‘
2. **åˆç†ä½¿ç”¨ Channel**: é¿å…é¢‘ç¹åˆ›å»º/é”€æ¯ Channel
3. **å¯ç”¨ PGO**: ä½¿ç”¨ Profile-Guided Optimization
4. **CPU äº²å’Œæ€§**: åœ¨ Linux ä¸Šè‡ªåŠ¨å¯ç”¨
5. **å‡å°‘é”ä½¿ç”¨**: ä½¿ç”¨æ— é”æ•°æ®ç»“æ„

### Q5: ä¸å…¶ä»–åç¨‹åº“çš„åŒºåˆ«ï¼Ÿ

| ç‰¹æ€§ | FlowCoro | cppcoro | Boost.Coroutine2 | Folly |
|------|----------|---------|------------------|-------|
| **suspend_never** | âœ… | âŒ | âŒ | âŒ |
| **æ— é”è°ƒåº¦** | âœ… | âŒ | âŒ | âœ… |
| **å¤šè°ƒåº¦å™¨** | âœ… | âŒ | âŒ | âœ… |
| **æ™ºèƒ½è´Ÿè½½å‡è¡¡** | âœ… | âŒ | âŒ | âœ… |
| **Channel é€šä¿¡** | âœ… | âœ… | âŒ | âŒ |
| **æ‰¹é‡å¤„ç†ä¼˜åŒ–** | âœ… | âŒ | âŒ | âœ… |

## æ€»ç»“

FlowCoro çš„è°ƒåº¦ç³»ç»Ÿè®¾è®¡å…·æœ‰ä»¥ä¸‹æ ¸å¿ƒç‰¹ç‚¹ï¼š

1. **ä¸‰å±‚æ¶æ„**: æ¸…æ™°çš„åˆ†å±‚è®¾è®¡ï¼ŒèŒè´£æ˜ç¡®
2. **ç«‹å³æ‰§è¡Œ**: suspend_never å®ç°ä»»åŠ¡åˆ›å»ºæ—¶ç«‹å³æ‰§è¡Œ
3. **æ— é”è®¾è®¡**: å…¨é¢é‡‡ç”¨æ— é”é˜Ÿåˆ—å’ŒåŸå­æ“ä½œ
4. **æ™ºèƒ½è´Ÿè½½å‡è¡¡**: æ··åˆè½®è¯¢å’Œè´Ÿè½½æ„ŸçŸ¥ç­–ç•¥
5. **æ‰¹é‡ä¼˜åŒ–**: æ‰€æœ‰å…³é”®è·¯å¾„éƒ½é‡‡ç”¨æ‰¹é‡å¤„ç†
6. **è‡ªé€‚åº”ç­‰å¾…**: å››çº§ç­‰å¾…ç­–ç•¥å¹³è¡¡å»¶è¿Ÿå’Œ CPU ä½¿ç”¨
7. **æ€§èƒ½ç›‘æ§**: å®Œå–„çš„ç»Ÿè®¡å’Œè°ƒè¯•å·¥å…·

è¿™äº›è®¾è®¡ä½¿ FlowCoro æˆä¸ºæ‰¹é‡ä»»åŠ¡å¤„ç†å’Œé«˜ååé‡åœºæ™¯çš„ç†æƒ³é€‰æ‹©ã€‚

---

## English Version

# FlowCoro Scheduling System Design

## Project Overview

FlowCoro is a high-performance C++20 coroutine library designed specifically for **batch task processing** and **high-throughput scenarios**.

### Core Features

- **Immediate Execution Model**: Tasks execute immediately upon creation using `suspend_never`
- **Lock-free Architecture**: High-performance task distribution based on lock-free queues
- **Smart Load Balancing**: Adaptive scheduler selection for load balancing
- **Multi-Scheduler Parallelism**: Multiple independent schedulers processing coroutines in parallel
- **Three-Layer Scheduling Architecture**: Clear layered design with well-defined responsibilities

### Best Use Cases

âœ… **Ideal For**:
- Web API servers (high-concurrency request handling)
- Batch data processing pipelines
- High-frequency trading systems
- Microservice gateways
- Web crawlers and parallel downloads
- Producer-consumer patterns (via Channels)

âŒ **Not Suitable For**:
- Scenarios requiring precise control over coroutine execution order
- Single long-running coroutines
- Scenarios requiring manual coroutine lifetime management

## Three-Layer Scheduling Architecture

FlowCoro employs a three-layer scheduling architecture with clear responsibilities at each layer:

```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 1: Coroutine Manager (CoroutineManager)      â”‚
â”‚  Role: Lifecycle management, timers, scheduling     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ schedule_coroutine_enhanced()
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 2: Coroutine Pool (CoroutinePool)            â”‚
â”‚  Role: Multi-scheduler management, load balancing   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ CoroutineScheduler (independent threads)
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Layer 3: Thread Pool (ThreadPool)                  â”‚
â”‚  Role: Worker thread management, lock-free executionâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Layer 1: Coroutine Manager

**Location**: `include/flowcoro/coroutine_manager.h`

**Core Responsibilities**:
1. Coroutine lifecycle management (creation, destruction)
2. Timer queue management (supports operations like `sleep_for`)
3. Scheduling decisions (submitting coroutines via `schedule_resume`)
4. Batch processing optimization (timers, ready queue, destruction queue)

**Key Methods**:

```cpp
class CoroutineManager {
public:
    // Core scheduling method - submits coroutines to the pool
    void schedule_resume(std::coroutine_handle<> handle);
    
    // Drives the scheduling loop (needs periodic calls from main thread)
    void drive();
    
    // Adds a timer
    void add_timer(std::chrono::steady_clock::time_point when, 
                   std::coroutine_handle<> handle);
    
    // Singleton pattern
    static CoroutineManager& get_instance();
};
```

**Batch Processing Optimization**:
- **Timer Queue**: Processes up to 32 expired timers at once
- **Ready Queue**: Processes up to 64 ready coroutines at once
- **Destruction Queue**: Batch destroys coroutines

### Layer 2: Coroutine Pool

**Location**: `src/coroutine_pool.cpp` (internal implementation)

**Core Responsibilities**:
1. Manages multiple independent coroutine schedulers (CoroutineScheduler)
2. Smart load balancing to select optimal scheduler
3. Statistics collection and performance monitoring
4. Manages background thread pool for CPU-intensive tasks

**Architecture Design**:

```cpp
class CoroutinePool {
private:
    // Number of schedulers based on CPU cores (currently configured as 1)
    const size_t NUM_SCHEDULERS;
    
    // Independent coroutine schedulers, each running in its own thread
    std::vector<std::unique_ptr<CoroutineScheduler>> schedulers_;
    
    // Background thread pool - handles CPU-intensive tasks
    std::unique_ptr<lockfree::ThreadPool> thread_pool_;
    
public:
    // Coroutine scheduling with smart load balancing
    void schedule_coroutine(std::coroutine_handle<> handle);
    
    // CPU-intensive tasks submitted to background thread pool
    void schedule_task(std::function<void()> task);
};
```

### Layer 3: Coroutine Scheduler

**Location**: `src/coroutine_pool.cpp` (internal implementation)

**Core Responsibilities**:
1. Runs in an independent thread, continuously processing coroutines
2. Manages lock-free coroutine queue
3. Batch executes coroutines for improved cache hit rate
4. Implements adaptive waiting strategy to reduce CPU spinning

**Key Features**:

```cpp
class CoroutineScheduler {
private:
    // Lock-free coroutine queue
    lockfree::Queue<std::coroutine_handle<>> coroutine_queue_;
    
    // Precise queue size tracking
    std::atomic<size_t> queue_size_{0};
    
    void worker_loop() {
        const size_t BATCH_SIZE = 256;
        std::vector<std::coroutine_handle<>> batch;
        
        while (!stop_flag_) {
            // Batch extract coroutines
            while (batch.size() < BATCH_SIZE && 
                   coroutine_queue_.dequeue(handle)) {
                batch.push_back(handle);
            }
            
            // Batch execute coroutines
            for (auto handle : batch) {
                if (handle && !handle.done()) {
                    handle.resume();
                }
            }
        }
    }
};
```

**Performance Optimizations**:
- **Batch Processing**: Processes up to 256 coroutines at once
- **Prefetching**: Uses `__builtin_prefetch` for improved cache hits
- **CPU Affinity**: Binds to specific CPU cores to reduce migration
- **Four-Level Waiting**: Adaptive waiting strategy based on idle time

## Smart Load Balancing

**Location**: `include/flowcoro/load_balancer.h`

### Design Goals

1. **Fast Selection**: Minimize scheduler selection overhead
2. **Load Balancing**: Avoid overloading certain schedulers
3. **Lock-free Design**: Use atomic operations to avoid lock contention

### Implementation

```cpp
class SmartLoadBalancer {
public:
    // Hybrid strategy: Round-robin + Load-aware
    size_t select_scheduler() {
        // Fast path: Use round-robin (better performance)
        size_t quick_choice = round_robin_counter_.fetch_add(1) % count;
        
        // Every 16 calls, perform load check
        if ((quick_choice & 0xF) == 0) {
            // Select scheduler with minimum load
            return find_minimum_load_scheduler();
        }
        
        return quick_choice;
    }
};
```

## Task Execution Flow

### Complete Execution Flow

```text
1. User creates Task
   â†“
2. Task constructor calls initial_suspend()
   â†“ (returns suspend_never)
3. Coroutine body begins execution immediately
   â†“
4. Encounters co_await (e.g., sleep_for)
   â†“ (returns suspend_always)
5. Coroutine suspends, submitted to CoroutineManager
   â†“
6-12. Scheduling through pool, load balancer, and execution
```

### suspend_never Mechanism

FlowCoro's key design is the **immediate execution** model:

```cpp
Task<int> compute(int x) {
    // 1. Task object created
    // 2. initial_suspend() returns suspend_never
    // 3. Coroutine body begins execution immediately (no scheduling wait)
    
    co_await sleep_for(std::chrono::milliseconds(50));
    // 4. Encounters co_await, returns suspend_always
    // 5. Now coroutine truly suspends and is submitted to scheduler
    
    co_return x * x;
}
```

**Advantages of suspend_never**:
1. **Maximizes Concurrency**: Tasks start executing immediately
2. **Reduces Latency**: Avoids "create â†’ wait for schedule â†’ start" delay
3. **Simplified API**: No manual task startup needed
4. **Natural Concurrency**: Multiple tasks automatically execute concurrently

## Performance Characteristics

### Throughput
- **Coroutine Creation/Execution**: Competitive with Go and Rust
- **Lock-free Queue**: Excellent performance under high concurrency
- **Batch Processing**: < 1 second for 100K tasks

### Latency
- **Task Scheduling**: Microsecond-level
- **Timer Precision**: Millisecond-level
- **Context Switching**: Extremely low (lock-free design)

### Scalability
- **CPU Cores**: Linear performance scaling (8-24 cores optimal)
- **Concurrent Tasks**: Supports 10K+ concurrent tasks
- **Scheduler Count**: Currently optimized for 1 (avoids excessive overhead)

## Summary

FlowCoro's scheduling system features:

1. **Three-Layer Architecture**: Clear separation of concerns
2. **Immediate Execution**: suspend_never for instant task startup
3. **Lock-free Design**: Comprehensive use of lock-free queues
4. **Smart Load Balancing**: Hybrid round-robin and load-aware strategy
5. **Batch Optimization**: All critical paths use batch processing
6. **Adaptive Waiting**: Four-level strategy balancing latency and CPU
7. **Performance Monitoring**: Comprehensive statistics and debugging tools

These designs make FlowCoro ideal for batch task processing and high-throughput scenarios.
