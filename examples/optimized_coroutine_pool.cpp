#include <iostream>
#include <vector>
#include <memory>
#include <chrono>
#include <atomic>
#include <queue>
#include <mutex>
#include <condition_variable>
#include <thread>
#include "../include/flowcoro.hpp"

// å­¦ä¹  Folly/CppCoro çš„åç¨‹æ± ä¼˜åŒ–è®¾è®¡
class OptimizedCoroutinePool {
public:
    // åç¨‹æ ˆå¤ç”¨æ±  - å€Ÿé‰´ IndexedMemPool è®¾è®¡
    struct CoroutineContext {
        std::coroutine_handle<> handle;
        std::atomic<bool> in_use{false};
        char stack_space[4096];  // é¢„åˆ†é…æ ˆç©ºé—´
        std::chrono::steady_clock::time_point last_used;
        
        void reset() {
            handle = {};
            in_use.store(false, std::memory_order_release);
            last_used = std::chrono::steady_clock::now();
        }
    };
    
    // çº¿ç¨‹æœ¬åœ°å­˜å‚¨æ±  - å€Ÿé‰´ static_thread_pool çš„ per-thread queue
    static thread_local std::vector<std::unique_ptr<CoroutineContext>> thread_local_pool;
    static thread_local size_t local_pool_index;
    
    // å…¨å±€åç¨‹æ±  - å­¦ä¹  Folly çš„å†…å­˜ç®¡ç†
    class GlobalCoroutinePool {
    private:
        std::vector<std::unique_ptr<CoroutineContext>> contexts_;
        std::queue<size_t> available_indices_;
        std::mutex mutex_;
        std::atomic<size_t> allocated_count_{0};
        std::atomic<size_t> peak_usage_{0};
        
        // å†…å­˜å›æ”¶ç­–ç•¥ - å€Ÿé‰´ MemoryIdler
        std::chrono::steady_clock::duration idle_timeout_{std::chrono::seconds(5)};
        std::thread cleanup_thread_;
        std::atomic<bool> shutdown_requested_{false};
        
    public:
        GlobalCoroutinePool(size_t initial_size = 100) {
            contexts_.reserve(initial_size * 2);  // é¢„ç•™å¢é•¿ç©ºé—´
            
            // é¢„åˆ†é…åç¨‹ä¸Šä¸‹æ–‡
            for (size_t i = 0; i < initial_size; ++i) {
                contexts_.emplace_back(std::make_unique<CoroutineContext>());
                available_indices_.push(i);
            }
            
            // å¯åŠ¨å†…å­˜æ¸…ç†çº¿ç¨‹
            cleanup_thread_ = std::thread([this] { cleanup_worker(); });
        }
        
        ~GlobalCoroutinePool() {
            shutdown_requested_.store(true);
            if (cleanup_thread_.joinable()) {
                cleanup_thread_.join();
            }
        }
        
        CoroutineContext* acquire() {
            std::lock_guard<std::mutex> lock(mutex_);
            
            if (available_indices_.empty()) {
                // åŠ¨æ€æ‰©å±• - å­¦ä¹  static_thread_pool çš„é˜Ÿåˆ—æ‰©å±•
                size_t old_size = contexts_.size();
                size_t new_size = std::min(old_size * 2, old_size + 50);  // é™åˆ¶å¢é•¿é€Ÿåº¦
                
                for (size_t i = old_size; i < new_size; ++i) {
                    contexts_.emplace_back(std::make_unique<CoroutineContext>());
                    available_indices_.push(i);
                }
                
                std::cout << "ğŸ“ˆ åç¨‹æ± æ‰©å±•: " << old_size << " â†’ " << new_size << " ä¸ªä¸Šä¸‹æ–‡" << std::endl;
            }
            
            if (!available_indices_.empty()) {
                size_t index = available_indices_.front();
                available_indices_.pop();
                
                auto* context = contexts_[index].get();
                context->in_use.store(true, std::memory_order_acquire);
                
                allocated_count_.fetch_add(1, std::memory_order_relaxed);
                
                // æ›´æ–°å³°å€¼ä½¿ç”¨é‡
                size_t current = allocated_count_.load();
                size_t peak = peak_usage_.load();
                while (current > peak && !peak_usage_.compare_exchange_weak(peak, current)) {
                    peak = peak_usage_.load();
                }
                
                return context;
            }
            
            return nullptr;
        }
        
        void release(CoroutineContext* context) {
            if (!context) return;
            
            context->reset();
            
            std::lock_guard<std::mutex> lock(mutex_);
            
            // æ‰¾åˆ°ä¸Šä¸‹æ–‡çš„ç´¢å¼•
            for (size_t i = 0; i < contexts_.size(); ++i) {
                if (contexts_[i].get() == context) {
                    available_indices_.push(i);
                    break;
                }
            }
            
            allocated_count_.fetch_sub(1, std::memory_order_relaxed);
        }
        
        // å†…å­˜ç»Ÿè®¡
        struct PoolStats {
            size_t total_contexts;
            size_t available_contexts;
            size_t allocated_contexts;
            size_t peak_usage;
            double utilization_rate;
        };
        
        PoolStats get_stats() const {
            std::lock_guard<std::mutex> lock(mutex_);
            
            PoolStats stats{};
            stats.total_contexts = contexts_.size();
            stats.available_contexts = available_indices_.size();
            stats.allocated_contexts = allocated_count_.load();
            stats.peak_usage = peak_usage_.load();
            stats.utilization_rate = stats.total_contexts > 0 ? 
                (double)stats.allocated_contexts / stats.total_contexts : 0.0;
            
            return stats;
        }
        
    private:
        void cleanup_worker() {
            while (!shutdown_requested_.load()) {
                std::this_thread::sleep_for(std::chrono::seconds(1));
                
                auto now = std::chrono::steady_clock::now();
                std::lock_guard<std::mutex> lock(mutex_);
                
                // å›æ”¶é•¿æ—¶é—´æœªä½¿ç”¨çš„ä¸Šä¸‹æ–‡ - å­¦ä¹  MemoryIdler ç­–ç•¥
                size_t cleaned = 0;
                for (auto& context : contexts_) {
                    if (!context->in_use.load() && 
                        (now - context->last_used) > idle_timeout_) {
                        // æ‰§è¡Œå†…å­˜æ¸…ç†æ“ä½œ
                        // è¿™é‡Œå¯ä»¥è°ƒç”¨ madvise ç­‰ç³»ç»Ÿè°ƒç”¨æ¥é‡Šæ”¾ç‰©ç†å†…å­˜
                        cleaned++;
                    }
                }
                
                if (cleaned > 0) {
                    std::cout << "ğŸ§¹ æ¸…ç†äº† " << cleaned << " ä¸ªç©ºé—²åç¨‹ä¸Šä¸‹æ–‡" << std::endl;
                }
            }
        }
    };
    
    static GlobalCoroutinePool& get_global_pool() {
        static GlobalCoroutinePool pool;
        return pool;
    }
    
    // æ™ºèƒ½åç¨‹å¥æŸ„ - è‡ªåŠ¨å›æ”¶
    class ManagedCoroutine {
    private:
        CoroutineContext* context_;
        
    public:
        ManagedCoroutine() : context_(get_global_pool().acquire()) {}
        
        ~ManagedCoroutine() {
            if (context_) {
                get_global_pool().release(context_);
            }
        }
        
        ManagedCoroutine(const ManagedCoroutine&) = delete;
        ManagedCoroutine& operator=(const ManagedCoroutine&) = delete;
        
        ManagedCoroutine(ManagedCoroutine&& other) noexcept 
            : context_(std::exchange(other.context_, nullptr)) {}
        
        ManagedCoroutine& operator=(ManagedCoroutine&& other) noexcept {
            if (this != &other) {
                if (context_) {
                    get_global_pool().release(context_);
                }
                context_ = std::exchange(other.context_, nullptr);
            }
            return *this;
        }
        
        CoroutineContext* get() const { return context_; }
        bool valid() const { return context_ != nullptr; }
    };
};

// çº¿ç¨‹æœ¬åœ°å­˜å‚¨åˆå§‹åŒ–
thread_local std::vector<std::unique_ptr<OptimizedCoroutinePool::CoroutineContext>> 
    OptimizedCoroutinePool::thread_local_pool;
thread_local size_t OptimizedCoroutinePool::local_pool_index = 0;

// ä¼˜åŒ–çš„åç¨‹ä»»åŠ¡ - ä½¿ç”¨å¯¹è±¡æ± 
template<typename T>
class OptimizedTask {
public:
    struct promise_type {
        std::optional<T> result;
        std::exception_ptr exception;
        OptimizedCoroutinePool::ManagedCoroutine managed_coro;
        
        OptimizedTask get_return_object() {
            return OptimizedTask{std::coroutine_handle<promise_type>::from_promise(*this)};
        }
        
        std::suspend_never initial_suspend() { return {}; }
        std::suspend_always final_suspend() noexcept { 
            return {}; 
        }
        
        void return_value(T value) {
            result = std::move(value);
        }
        
        void unhandled_exception() {
            exception = std::current_exception();
        }
    };
    
private:
    std::coroutine_handle<promise_type> handle_;
    
public:
    explicit OptimizedTask(std::coroutine_handle<promise_type> h) : handle_(h) {}
    
    ~OptimizedTask() {
        if (handle_) {
            handle_.destroy();
        }
    }
    
    OptimizedTask(const OptimizedTask&) = delete;
    OptimizedTask& operator=(const OptimizedTask&) = delete;
    
    OptimizedTask(OptimizedTask&& other) noexcept 
        : handle_(std::exchange(other.handle_, {})) {}
    
    OptimizedTask& operator=(OptimizedTask&& other) noexcept {
        if (this != &other) {
            if (handle_) {
                handle_.destroy();
            }
            handle_ = std::exchange(other.handle_, {});
        }
        return *this;
    }
    
    T get() {
        if (handle_.promise().exception) {
            std::rethrow_exception(handle_.promise().exception);
        }
        return *handle_.promise().result;
    }
    
    bool ready() const {
        return handle_.done();
    }
};

// ä½¿ç”¨ç¤ºä¾‹ï¼šä¼˜åŒ–çš„HTTPè¯·æ±‚å¤„ç†
OptimizedTask<std::string> optimized_http_request(int request_id) {
    // æ¨¡æ‹ŸHTTPè¯·æ±‚å¤„ç†
    std::this_thread::sleep_for(std::chrono::milliseconds(50));
    co_return "Response for request " + std::to_string(request_id);
}

// æ€§èƒ½æµ‹è¯•å‡½æ•°
void benchmark_optimized_coroutines(int request_count) {
    auto start = std::chrono::high_resolution_clock::now();
    
    std::vector<OptimizedTask<std::string>> tasks;
    tasks.reserve(request_count);
    
    // åˆ›å»ºä»»åŠ¡
    for (int i = 0; i < request_count; ++i) {
        tasks.emplace_back(optimized_http_request(i));
    }
    
    // ç­‰å¾…å®Œæˆ
    for (auto& task : tasks) {
        while (!task.ready()) {
            std::this_thread::sleep_for(std::chrono::microseconds(100));
        }
    }
    
    auto end = std::chrono::high_resolution_clock::now();
    auto duration = std::chrono::duration_cast<std::chrono::milliseconds>(end - start);
    
    // è·å–æ± ç»Ÿè®¡
    auto stats = OptimizedCoroutinePool::get_global_pool().get_stats();
    
    std::cout << "ğŸš€ ä¼˜åŒ–åç¨‹æµ‹è¯•å®Œæˆ:" << std::endl;
    std::cout << "   è¯·æ±‚æ•°é‡: " << request_count << std::endl;
    std::cout << "   æ€»è€—æ—¶: " << duration.count() << " ms" << std::endl;
    std::cout << "   ååé‡: " << (request_count * 1000 / duration.count()) << " è¯·æ±‚/ç§’" << std::endl;
    std::cout << std::endl;
    
    std::cout << "ğŸ“Š åç¨‹æ± ç»Ÿè®¡:" << std::endl;
    std::cout << "   æ€»ä¸Šä¸‹æ–‡æ•°: " << stats.total_contexts << std::endl;
    std::cout << "   å¯ç”¨ä¸Šä¸‹æ–‡: " << stats.available_contexts << std::endl;
    std::cout << "   å·²åˆ†é…ä¸Šä¸‹æ–‡: " << stats.allocated_contexts << std::endl;
    std::cout << "   å³°å€¼ä½¿ç”¨é‡: " << stats.peak_usage << std::endl;
    std::cout << "   åˆ©ç”¨ç‡: " << std::fixed << std::setprecision(1) 
              << (stats.utilization_rate * 100) << "%" << std::endl;
}

int main() {
    std::cout << "========================================" << std::endl;
    std::cout << "ğŸ¯ ä¼˜åŒ–åç¨‹æ± å†…å­˜ç®¡ç†æµ‹è¯•" << std::endl;
    std::cout << "========================================" << std::endl;
    std::cout << "ğŸ“š å€Ÿé‰´ä¼˜ç§€å¼€æºé¡¹ç›®è®¾è®¡:" << std::endl;
    std::cout << "   â€¢ Folly IndexedMemPool - å¯¹è±¡æ± å¤ç”¨" << std::endl;
    std::cout << "   â€¢ CppCoro static_thread_pool - å·¥ä½œçªƒå–" << std::endl;
    std::cout << "   â€¢ Folly MemoryIdler - å†…å­˜å›æ”¶ç­–ç•¥" << std::endl;
    std::cout << "========================================" << std::endl;
    std::cout << std::endl;
    
    // æµ‹è¯•ä¸åŒè§„æ¨¡
    std::vector<int> test_sizes = {100, 500, 1000, 2000};
    
    for (int size : test_sizes) {
        std::cout << "ğŸ”¸ æµ‹è¯• " << size << " ä¸ªåç¨‹:" << std::endl;
        benchmark_optimized_coroutines(size);
        std::cout << std::endl;
        
        // ç­‰å¾…ä¸€ä¸‹ï¼Œè®©æ¸…ç†çº¿ç¨‹å·¥ä½œ
        std::this_thread::sleep_for(std::chrono::milliseconds(500));
    }
    
    std::cout << "ğŸ’¡ ä¼˜åŒ–è¦ç‚¹æ€»ç»“:" << std::endl;
    std::cout << "   âœ… åç¨‹ä¸Šä¸‹æ–‡å¤ç”¨ - å‡å°‘åŠ¨æ€åˆ†é…" << std::endl;
    std::cout << "   âœ… é¢„åˆ†é…æ ˆç©ºé—´ - é¿å…è¿è¡Œæ—¶åˆ†é…" << std::endl;
    std::cout << "   âœ… çº¿ç¨‹æœ¬åœ°ç¼“å­˜ - å‡å°‘é”ç«äº‰" << std::endl;
    std::cout << "   âœ… æ™ºèƒ½å†…å­˜å›æ”¶ - è‡ªåŠ¨æ¸…ç†ç©ºé—²èµ„æº" << std::endl;
    std::cout << "   âœ… åŠ¨æ€æ± æ‰©å±• - æŒ‰éœ€å¢é•¿å®¹é‡" << std::endl;
    std::cout << "   âœ… è¯¦ç»†å†…å­˜ç»Ÿè®¡ - ç›‘æ§å†…å­˜ä½¿ç”¨æƒ…å†µ" << std::endl;
    
    return 0;
}
